import asyncio
import aiohttp
import json
import re
import requests
import os
from typing import Dict, List, Optional, Tuple
from aiohttp import FormData

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
ACCOUNTS_FILE = "accounts.json"
COOKIES_DIR = "cookies"
PREFERENCES_FILE = "preferences.json"

# –û–ø—Ü–∏–∏ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã
EXPERIENCE_OPTIONS = {
    "1": {"label": "–ù–µ—Ç –æ–ø—ã—Ç–∞", "value": "noExperience"},
    "2": {"label": "–û—Ç 1 –¥–æ 3 –ª–µ—Ç", "value": "between1And3"},
    "3": {"label": "–û—Ç 3 –¥–æ 6 –ª–µ—Ç", "value": "between3And6"},
    "4": {"label": "–ë–æ–ª–µ–µ 6 –ª–µ—Ç", "value": "moreThan6"}
}

class Resume:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—é–º–µ."""
    
    def __init__(self, hash: str, query: str, blacklist: List[str] = None):
        self.hash = hash
        self.query = query  # –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ä–µ–∑—é–º–µ
        self.blacklist = blacklist or []  # –°–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–∞–µ–º—ã—Ö —Å–ª–æ–≤/—Ñ—Ä–∞–∑

class Account:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–∫–∫–∞—É–Ω—Ç–æ–º –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–∫–ª–∏–∫–æ–≤ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏."""
    
    def __init__(self, email: str, resumes: List[Resume]):
        self.email = email
        self.resumes = resumes
        self.cookies = {}
        self.is_token_being_updated = False
        self.load_cookies()

    def get_cookies_file_path(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∫—É–∫–∞–º–∏ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞."""
        return os.path.join(COOKIES_DIR, f"{self.email}.json")

    def load_cookies(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—É–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞."""
        cookies_file = self.get_cookies_file_path()
        if os.path.exists(cookies_file):
            try:
                with open(cookies_file, "r", encoding="utf-8") as file:
                    data = json.load(file)
                    self.cookies = data.get("cookies", {})
            except (json.JSONDecodeError, FileNotFoundError):
                self.cookies = {}

    def update_cookies(self, cookies: Dict[str, str]) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∫—É–∫–∏ –≤ –æ–±—ä–µ–∫—Ç–µ."""
        self.cookies.update(cookies)

    def save_cookies_to_file(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫—É–∫–∏ –≤ —Ñ–∞–π–ª."""
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É cookies, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(COOKIES_DIR, exist_ok=True)
        
        cookies_file = self.get_cookies_file_path()
        data = {"cookies": self.cookies}
        
        with open(cookies_file, "w", encoding="utf-8") as file:
            json.dump(data, file, indent=4)

    def prompt_cookies_update(self) -> None:
        """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–æ–≤—ã–µ –∫—É–∫–∏ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∏—Ö."""
        self.is_token_being_updated = True
        new_cookies = parse_cookies(input(f"–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–µ –∫—É–∫–∏ –¥–ª—è {self.email}: "))
        self.update_cookies(new_cookies)
        self.save_cookies_to_file()
        self.is_token_being_updated = False

    async def respond_to_vacancy(self, vacancy_id: int, resume: Resume) -> Dict[str, str | bool]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–∫–ª–∏–∫ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é –∏—Å–ø–æ–ª—å–∑—É—è —É–∫–∞–∑–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ."""
        url = "https://hh.ru/applicant/vacancy_response/popup"
        payload = {
            "resume_hash": resume.hash,
            "vacancy_id": str(vacancy_id),
            "lux": "true",
            "ignore_postponed": "true",
            "mark_applicant_visible_in_vacancy_country": "false",
        }
        
        form_data = FormData()
        for key, value in payload.items():
            form_data.add_field(key, value)

        headers = {
            "User-Agent": "Mozilla/5.0",
            "X-Xsrftoken": self.cookies.get("_xsrf", ""),
            "Accept": "application/json",
            "Cookie": cookies_to_string(self.cookies),
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(url, data=form_data, headers=headers) as response:
                text = await response.text()
                
                if response.status == 403:
                    print(f"403 Forbidden: {text[:100]}")
                    if not self.is_token_being_updated:
                        self.prompt_cookies_update()
                    else:
                        while self.is_token_being_updated:
                            await asyncio.sleep(5)
                    return await self.respond_to_vacancy(vacancy_id, resume)
                
                try:
                    data = json.loads(text)
                except json.JSONDecodeError:
                    print(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON-–æ—Ç–≤–µ—Ç. –°—Ç–∞—Ç—É—Å: {response.status}, –¢–µ–∫—Å—Ç: {text}")
                    return {"success": False, "error": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON-–æ—Ç–≤–µ—Ç"}

                if "error" in data:
                    return {"success": False, "error": data["error"]}
                
                if data.get("type") == "need-login":
                    if not self.is_token_being_updated:
                        self.prompt_cookies_update()
                    else:
                        while self.is_token_being_updated:
                            await asyncio.sleep(5)
                    return await self.respond_to_vacancy(vacancy_id, resume)
                
                success_result = {"success": data.get("success") == "true"}
                if success_result["success"]:
                    success_result["resume_used"] = resume.query
                return success_result

class AccountResumePair:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ä—ã –∞–∫–∫–∞—É–Ω—Ç-—Ä–µ–∑—é–º–µ."""
    
    def __init__(self, account: Account, resume: Resume, pair_id: int):
        self.account = account
        self.resume = resume
        self.pair_id = pair_id
        self.is_exhausted = False

def display_accounts_info(accounts: List[Account]) -> None:
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–∫–∫–∞—É–Ω—Ç–∞—Ö –∏ –∏—Ö —Ä–µ–∑—é–º–µ."""
    print("\n=== –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û–ë –ê–ö–ö–ê–£–ù–¢–ê–• ===")
    for i, account in enumerate(accounts, 1):
        print(f"\n–ê–∫–∫–∞—É–Ω—Ç {i}: {account.email}")
        for j, resume in enumerate(account.resumes, 1):
            blacklist_info = f" (–∏—Å–∫–ª—é—á–µ–Ω–∏—è: {', '.join(resume.blacklist)})" if resume.blacklist else ""
            print(f"  –†–µ–∑—é–º–µ {j}: {resume.query}{blacklist_info}")

def load_preferences() -> Dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    if os.path.exists(PREFERENCES_FILE):
        try:
            with open(PREFERENCES_FILE, "r", encoding="utf-8") as file:
                return json.load(file)
        except json.JSONDecodeError:
            return {}
    return {}

def save_preferences(preferences: Dict) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    with open(PREFERENCES_FILE, "w", encoding="utf-8") as file:
        json.dump(preferences, file, indent=4)

def use_saved_settings() -> Dict:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å."""
    preferences = load_preferences()
    
    if not preferences:
        return {"use_saved": False}
    
    has_experience = "experience" in preferences and preferences["experience"]
    has_search_order = "search_order" in preferences and preferences["search_order"]
    
    if not (has_experience or has_search_order):
        return {"use_saved": False}
    
    print("\n=== –°–û–•–†–ê–ù–ï–ù–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò ===")
    
    if has_experience:
        experience_labels = [
            next((opt['label'] for opt in EXPERIENCE_OPTIONS.values() if opt['value'] == exp), exp) 
            for exp in preferences["experience"]
        ]
        print(f"–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: {', '.join(experience_labels)}")
    
    if has_search_order:
        print("–ü–æ—Ä—è–¥–æ–∫ –ø–æ–∏—Å–∫–∞: —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
    
    print("\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏? (y/n)")
    user_choice = input("–í–∞—à –≤—ã–±–æ—Ä: ").strip().lower()
    
    if user_choice in ['y', 'yes', '–¥–∞', '']:
        return {
            "use_saved": True,
            "experience": preferences.get("experience", []),
            "search_order": preferences.get("search_order", {})
        }
    else:
        return {"use_saved": False}

def get_experience_from_user() -> List[str]:
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã."""
    preferences = load_preferences()
    saved_experience = preferences.get("experience", [])
    
    print("\n=== –í–´–ë–û–† –û–ü–´–¢–ê –†–ê–ë–û–¢–´ ===")
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:")
    
    for key, option in EXPERIENCE_OPTIONS.items():
        saved_mark = " (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ)" if option["value"] in saved_experience else ""
        print(f"{key}. {option['label']}{saved_mark}")
    
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1 2)")
    if saved_experience:
        print(f"–ù–∞–∂–º–∏—Ç–µ Enter, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã")
    
    while True:
        user_input = input("\n–í–∞—à –≤—ã–±–æ—Ä: ").strip()
        
        if not user_input and saved_experience:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
            print(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã")
            return saved_experience
        
        try:
            # –ü–∞—Ä—Å–∏–º –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            selected_keys = user_input.split()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤–≤–µ–¥–µ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤
            if not all(key in EXPERIENCE_OPTIONS for key in selected_keys):
                print("–û—à–∏–±–∫–∞: –í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞")
                continue
                
            if not selected_keys:
                print("–û—à–∏–±–∫–∞: –í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç")
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –æ–ø—Ü–∏–π
            selected_experience = [EXPERIENCE_OPTIONS[key]["value"] for key in selected_keys]
            
            # –°–ø—Ä–∞—à–∏–≤–∞–µ–º, —Ö–æ—á–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—ã–±–æ—Ä
            save_choice = input("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç–æ—Ç –≤—ã–±–æ—Ä? (y/n): ").strip().lower()
            if save_choice in ['y', 'yes', '–¥–∞', '']:
                preferences["experience"] = selected_experience
                save_preferences(preferences)
                print("–í—ã–±–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
            
            return selected_experience
            
        except ValueError:
            print("–û—à–∏–±–∫–∞: –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1 2)")
            continue

def get_search_order_from_user(all_search_queries: List[str]) -> List[str]:
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤."""
    preferences = load_preferences()
    saved_order = preferences.get("search_order", {})
    
    print("\n=== –í–´–ë–û–† –ü–û–†–Ø–î–ö–ê –û–¢–ö–õ–ò–ö–ê –ù–ê –í–ê–ö–ê–ù–°–ò–ò ===")
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã:")
    
    for i, query in enumerate(all_search_queries, 1):
        saved_position = saved_order.get(query, -1)
        saved_info = f" (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {saved_position})" if saved_position > 0 else ""
        print(f"{i}. {query}{saved_info}")
    
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ")
    print("–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ª–∏–º–∏—Ç–∞ –≤ 200 –æ—Ç–∫–ª–∏–∫–æ–≤ –Ω–∞ –∫–∞–∂–¥—ã–π –∞–∫–∫–∞—É–Ω—Ç.")
    print("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2 1 3)")
    
    if saved_order and len(saved_order) == len(all_search_queries):
        print("–ò–ª–∏ –Ω–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞")
    else:
        print("–ò–ª–∏ –Ω–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞")
    
    while True:
        user_input = input("\n–í–∞—à –≤—ã–±–æ—Ä: ").strip()
        
        if not user_input:
            # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –≤—ã–±—Ä–∞–ª –ø–æ—Ä—è–¥–æ–∫
            if saved_order and len(saved_order) == len(all_search_queries):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
                ordered_queries = sorted(all_search_queries, key=lambda q: saved_order.get(q, 999))
                print("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫")
                return ordered_queries
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
                print("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫")
                return all_search_queries
        
        try:
            # –ü–∞—Ä—Å–∏–º –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            selected_indices = [int(x) - 1 for x in user_input.split()]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤–≤–µ–¥–µ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤
            if len(selected_indices) != len(all_search_queries):
                print(f"–û—à–∏–±–∫–∞: –ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å {len(all_search_queries)} –Ω–æ–º–µ—Ä–æ–≤")
                continue
                
            if any(i < 0 or i >= len(all_search_queries) for i in selected_indices):
                print(f"–û—à–∏–±–∫–∞: –ù–æ–º–µ—Ä–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Ç 1 –¥–æ {len(all_search_queries)}")
                continue
                
            if len(set(selected_indices)) != len(selected_indices):
                print("–û—à–∏–±–∫–∞: –ù–æ–º–µ—Ä–∞ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è")
                continue
            
            # –°–æ–∑–¥–∞–µ–º —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
            ordered_queries = [all_search_queries[i] for i in selected_indices]
            
            print("\n–í—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫:")
            for i, query in enumerate(ordered_queries, 1):
                print(f"{i}. {query}")
            
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            confirm = input("\n–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å? (y/n): ").strip().lower()
            if confirm in ['y', 'yes', '–¥–∞', '']:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫
                new_order = {query: i+1 for i, query in enumerate(ordered_queries)}
                preferences = load_preferences()
                preferences["search_order"] = new_order
                save_preferences(preferences)
                print("–ü–æ—Ä—è–¥–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
                return ordered_queries
            else:
                print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑")
                continue
                
        except ValueError:
            print("–û—à–∏–±–∫–∞: –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2 1 3)")
            continue

async def get_vacancies_data(session: aiohttp.ClientSession, params: str) -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö —Å —Å–∞–π—Ç–∞."""
    url = f"https://hh.ru/search/vacancy?{params}"
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "*/*",
        "X-Static-Version": website_version,
        "X-Xsrftoken": "1",
    }
    
    async with session.get(url, headers=headers) as response:
        text = await response.text()
        match = re.search(r'{"topLevelSite".*"action":"POP"}}', text)
        if not match:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö –∏–∑ –æ—Ç–≤–µ—Ç–∞")
        return json.loads(match.group(0))

async def get_vacancies(session: aiohttp.ClientSession, request: str, page: int, experience_list: List[str]) -> List[Dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
    all_vacancies = []
    
    for experience in experience_list:
        params = f"text={request}&salary=&ored_clusters=true&experience={experience}&page={page}"
        data = await get_vacancies_data(session, params)
        all_vacancies.extend(data["vacancySearchResult"]["vacancies"])
    
    return all_vacancies

async def get_vacancies_pages(session: aiohttp.ClientSession, request: str, experience_list: List[str]) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –æ–ø—ã—Ç–æ–≤."""
    max_pages = 0
    
    for experience in experience_list:
        params = f"text={request}&salary=&ored_clusters=true&experience={experience}&page=1"
        data = await get_vacancies_data(session, params)
        paging = data["vacancySearchResult"]["paging"]
        
        if paging is None:
            current_pages = 1
        else:
            current_pages = data["vacancySearchResult"]["paging"]["lastPage"]["page"]
        
        max_pages = max(max_pages, current_pages)
    
    return max_pages

def is_vacancy_blacklisted(vacancy_name: str, blacklist: List[str]) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏—Å–∫–ª—é—á–∞–µ–º—ã–µ —Å–ª–æ–≤–∞."""
    if not blacklist:
        return False
    
    vacancy_name_lower = vacancy_name.lower()
    return any(word.lower() in vacancy_name_lower for word in blacklist)

async def process_vacancy(
    vacancy: Dict,
    relevant_pairs: List[AccountResumePair],  # –¢–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø–∞—Ä—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    exhausted_pairs: List[int],
    pair_lock: asyncio.Lock,
    pair_index: List[int]
) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏—é –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–∫–ª–∏–∫, –µ—Å–ª–∏ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ."""
    name = vacancy["name"]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º blacklist –¥–ª—è –ø–µ—Ä–≤–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –ø–∞—Ä—ã (—É –≤—Å–µ—Ö –ø–∞—Ä –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π query –∏ blacklist)
    if relevant_pairs and is_vacancy_blacklisted(name, relevant_pairs[0].resume.blacklist):
        print(f"–í–∞–∫–∞–Ω—Å–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞ (blacklist): {name}")
        return

    async with pair_lock:
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–∏—Å—á–µ—Ä–ø–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö
        available_pairs = [pair for pair in relevant_pairs if pair.pair_id not in exhausted_pairs]
        
        if not available_pairs:
            print(f"–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–∫–ª–∏–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é: {name}")
            return
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø–∞—Ä—É –ø–æ –∫—Ä—É–≥–æ–≤–æ–º—É –ø—Ä–∏–Ω—Ü–∏–ø—É —Å—Ä–µ–¥–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
        pair = available_pairs[pair_index[0] % len(available_pairs)]
        curr_pair_id = pair.pair_id
        pair_index[0] = (pair_index[0] + 1) % len(available_pairs)

    resp = await pair.account.respond_to_vacancy(vacancy["vacancyId"], pair.resume)
    if resp["success"]:
        print(f"–û—Ç–∫–ª–∏–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é: {name} (—Ä–µ–∑—é–º–µ: {pair.resume.query}, –∞–∫–∫–∞—É–Ω—Ç: {pair.account.email})")
    else:
        error = resp["error"]
        if error == "negotiations-limit-exceeded":
            print(f"–õ–∏–º–∏—Ç –æ—Ç–∫–ª–∏–∫–æ–≤ –∞–∫–∫–∞—É–Ω—Ç–∞ {pair.account.email} –∏—Å—á–µ—Ä–ø–∞–Ω.")
            async with pair_lock:
                if curr_pair_id not in exhausted_pairs:
                    exhausted_pairs.append(curr_pair_id)
        elif error != "unknown":
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫–ª–∏–∫–Ω—É—Ç—å—Å—è –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é {name}: {error}")

async def process_resume_vacancies(
    session: aiohttp.ClientSession,
    search_query: str,
    relevant_pairs: List[AccountResumePair],  # –¢–æ–ª—å–∫–æ –ø–∞—Ä—ã, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    exhausted_pairs: List[int],
    pair_lock: asyncio.Lock,
    pair_index: List[int],
    experience_list: List[str]
) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
    print(f"\n=== –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {search_query} ===")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä—ã –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    available_pairs = [pair for pair in relevant_pairs if pair.pair_id not in exhausted_pairs]
    if not available_pairs:
        print(f"–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {search_query}")
        return
    
    print(f"–î–æ—Å—Ç—É–ø–Ω–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è '{search_query}': {len(available_pairs)}")
    for pair in available_pairs:
        print(f"  - {pair.account.email}")
    
    last_page = await get_vacancies_pages(session, search_query, experience_list)
    print(f"–ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è '{search_query}': {last_page}")
    
    for page in range(0, last_page + 1):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä—ã –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π
        available_pairs = [pair for pair in relevant_pairs if pair.pair_id not in exhausted_pairs]
        if not available_pairs:
            print(f"\n‚ùå –õ–∏–º–∏—Ç –≤—Å–µ—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{search_query}' –∏—Å—á–µ—Ä–ø–∞–Ω.")
            break
            
        vacancies = await get_vacancies(session, search_query, page, experience_list)
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}/{last_page} –¥–ª—è '{search_query}' ({len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π)")
        
        tasks = [
            process_vacancy(vacancy, relevant_pairs, exhausted_pairs, pair_lock, pair_index)
            for vacancy in vacancies
        ]
        await asyncio.gather(*tasks)
    
    print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {search_query}")

def cookies_to_string(cookies: Dict[str, str]) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ª–æ–≤–∞—Ä—å –∫—É–∫ –≤ —Å—Ç—Ä–æ–∫—É."""
    return "; ".join(f"{key}={value}" for key, value in cookies.items())

def parse_cookies(cookie_str: str) -> Dict[str, str]:
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –∫—É–∫ –≤ —Å–ª–æ–≤–∞—Ä—å."""
    return dict(cookie.strip().split("=", 1) for cookie in cookie_str.split(";"))

def get_website_version() -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤–µ—Ä—Å–∏—é —Å–∞–π—Ç–∞ hh.ru."""
    url = "https://hh.ru/?hhtmFrom=resume_list"
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    }
    response = requests.get(url, headers=headers)
    version = re.search(r"[1-9]{0,2}\.[1-9]{0,2}\.[1-9]{0,2}\.[1-9]{0,2}", response.text)
    if not version:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤–µ—Ä—Å–∏—é —Å–∞–π—Ç–∞")
    return version.group(0)

async def main() -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã."""
    try:
        with open(ACCOUNTS_FILE, "r", encoding="utf-8") as file:
            accounts_data = json.load(file)
    except FileNotFoundError:
        print(f"–§–∞–π–ª {ACCOUNTS_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    # –°–æ–∑–¥–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã –∏ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    accounts = []
    all_search_queries = set()
    
    for account_data in accounts_data:
        resumes = [
            Resume(
                hash=resume["hash"], 
                query=resume["search_criteria"]["query"],
                blacklist=resume["search_criteria"].get("exclude_words", [])
            ) 
            for resume in account_data["resumes"]
        ]
        if resumes:  # –°–æ–∑–¥–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—é–º–µ
            accounts.append(Account(email=account_data["email"], resumes=resumes))
            for resume in resumes:
                all_search_queries.add(resume.query)

    if not accounts:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ —Å —Ä–µ–∑—é–º–µ.")
        return

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–∫–∫–∞—É–Ω—Ç–∞—Ö
    display_accounts_info(accounts)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
    saved_settings = use_saved_settings()
    all_search_queries_list = list(all_search_queries)

    if saved_settings["use_saved"]:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        experience_list = saved_settings.get("experience", [])
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –ø–æ–∏—Å–∫–∞, –ø—Ä–∏–º–µ–Ω—è–µ–º –µ–≥–æ
        if saved_settings.get("search_order"):
            ordered_search_queries = sorted(
                all_search_queries_list, 
                key=lambda q: saved_settings["search_order"].get(q, 999)
            )
        else:
            ordered_search_queries = all_search_queries_list
            
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
        experience_labels = [
            next((opt['label'] for opt in EXPERIENCE_OPTIONS.values() if opt['value'] == exp), exp) 
            for exp in experience_list
        ]
        print(f"\n–í—ã–±—Ä–∞–Ω—ã –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã: {', '.join(experience_labels)}")
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –ø–æ–∏—Å–∫–∞")
    else:
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
        experience_list = get_experience_from_user()
        experience_labels = [
            next((opt['label'] for opt in EXPERIENCE_OPTIONS.values() if opt['value'] == exp), exp) 
            for exp in experience_list
        ]
        print(f"\n–í—ã–±—Ä–∞–Ω—ã –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã: {', '.join(experience_labels)}")

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        ordered_search_queries = get_search_order_from_user(all_search_queries_list)

    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—ã –∞–∫–∫–∞—É–Ω—Ç-—Ä–µ–∑—é–º–µ
    account_resume_pairs = []
    pair_id = 0
    
    for account in accounts:
        for resume in account.resumes:
            account_resume_pairs.append(AccountResumePair(account, resume, pair_id))
            pair_id += 1

    if not account_resume_pairs:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–∞—Ä –∞–∫–∫–∞—É–Ω—Ç-—Ä–µ–∑—é–º–µ.")
        return

    print(f"\n=== –ù–ê–ß–ê–õ–û –û–ë–†–ê–ë–û–¢–ö–ò ===")
    print(f"–°–æ–∑–¥–∞–Ω–æ {len(account_resume_pairs)} –ø–∞—Ä –∞–∫–∫–∞—É–Ω—Ç-—Ä–µ–∑—é–º–µ")
    print(f"–ü–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤: {' ‚Üí '.join(ordered_search_queries)}")

    exhausted_pairs: List[int] = []
    pair_lock = asyncio.Lock()

    session_headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "application/json",
        "X-Static-Version": website_version,
        "X-Xsrftoken": "1",
    }

    async with aiohttp.ClientSession(headers=session_headers) as session:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –ø–æ—Ä—è–¥–∫–µ
        for search_query in ordered_search_queries:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–∞—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω–æ–º—É –ø–æ–∏—Å–∫–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É
            relevant_pairs = [
                pair for pair in account_resume_pairs 
                if pair.resume.query == search_query
            ]
            
            if not relevant_pairs:
                print(f"–ù–µ—Ç –ø–∞—Ä –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {search_query}")
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä—ã
            available_pairs = [pair for pair in relevant_pairs if pair.pair_id not in exhausted_pairs]
            if not available_pairs:
                print(f"–í—Å–µ –∞–∫–∫–∞—É–Ω—Ç—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{search_query}' –∏—Å—á–µ—Ä–ø–∞–Ω—ã.")
                continue
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            pair_index = [0]
            
            await process_resume_vacancies(
                session, search_query, relevant_pairs, 
                exhausted_pairs, pair_lock, pair_index, experience_list
            )

    print(f"\nüéâ –ü–†–û–ì–†–ê–ú–ú–ê –ó–ê–í–ï–†–®–ï–ù–ê!")

if __name__ == "__main__":
    website_version = get_website_version()
    asyncio.run(main())